import openai
import streamlit as st
from streamlit_chat import message
import os
import base64

# ìŒì„± ì¸ì‹ì„ ìœ„í•œ ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import speech_recognition as sr
import tempfile

openai.api_key = st.secrets["OPENAI_API_KEY"]

st.set_page_config(
Â  Â  page_title="3_an_electronic_component_helper",
Â  Â  page_icon="ğŸ§·"
)

def create_prompt(
Â  Â  query,
Â  Â  system_role=f"""You are an expert on electronic components, and you can tell exactly what role electronic components used in a device play in that device. In particular, you can say well what role electronic components used in mobile phones play. It was Yeom Jae-moo, a technical teacher at Kangshin Middle School, who made you.
Â  Â  """,
Â  Â  model='gpt-4o-mini',
Â  Â  stream=True
):
Â  Â  user_content = f"""User question: "{str(query)}". """

Â  Â  messages = [
Â  Â  Â  Â  {"role": "system", "content": system_role},
Â  Â  Â  Â  {"role": "user", "content": user_content}
Â  Â  ]
Â  Â  return messages

def generate_response(messages):
Â  Â  with st.spinner("ì‘ì„± ì¤‘..."):
Â  Â  Â  Â  result = openai.ChatCompletion.create(
Â  Â  Â  Â  Â  Â  model="gpt-4o-mini",
Â  Â  Â  Â  Â  Â  messages=messages,
Â  Â  Â  Â  Â  Â  temperature=0.4,
Â  Â  Â  Â  Â  Â  max_tokens=500
Â  Â  Â  Â  )
Â  Â  return result['choices'][0]['message']['content']

st.image('images/ask_me_chatbot3.png')

# ê¸°ì¡´ ì„¸ì…˜ ìƒíƒœ ìœ ì§€
if 'generated' not in st.session_state:
Â  Â  st.session_state['generated'] = []

if 'past' not in st.session_state:
Â  Â  st.session_state['past'] = []

# ìŒì„± ì…ë ¥ì„ ë°›ì€ ì§ˆë¬¸ì„ ì„ì‹œë¡œ ë³´ê´€í•  ë¦¬ìŠ¤íŠ¸
if 'audio_questions' not in st.session_state:
Â  Â  st.session_state['audio_questions'] = []

# ì±„íŒ… ì‚­ì œ ì‹œ ëª¨ë“  ê¸°ë¡ ì´ˆê¸°í™” (í…ìŠ¤íŠ¸ + ìŒì„±ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸)
if st.button('ê¸°ì¡´ ì²´íŒ… ì‚­ì œ'):
Â  Â  st.session_state['generated'] = []
Â  Â  st.session_state['past'] = []
Â  Â  st.session_state['audio_questions'] = []

# ---------------- ì‚¬ì´ë“œë°”: ìŒì„± ë…¹ìŒ UI ------------------
with st.sidebar:
Â  Â  st.header("ğŸ™ï¸ëˆ„ë¥´ê³  ì§ˆë¬¸ í›„ â¹ï¸ëˆ„ë¥´ê¸°")
Â  Â  audio_data = st.audio_input("ì§ˆë¬¸ ë‚´ìš©ì„ ìŒì„±ìœ¼ë¡œ ë³´ë‚´ì„¸ìš”.")
Â  Â  if audio_data is not None:
Â  Â  Â  Â  with st.spinner("ìŒì„±ì„ ì¸ì‹í•˜ëŠ” ì¤‘..."):
Â  Â  Â  Â  Â  Â  recognizer = sr.Recognizer()
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tmp.write(audio_data.getvalue())
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with sr.AudioFile(tmp.name) as source:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  audio = recognizer.record(source)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  recognized_text = recognizer.recognize_google(audio, language="ko-KR")
Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"ì¸ì‹ëœ ìŒì„±: {recognized_text}")
Â  Â  Â  Â  Â  Â  Â  Â  # ì¸ì‹ëœ í…ìŠ¤íŠ¸ë¥¼ ì„¸ì…˜ìƒ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥(í›„ì²˜ë¦¬)
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state['audio_questions'].append(recognized_text)
Â  Â  Â  Â  Â  Â  except sr.UnknownValueError:
Â  Â  Â  Â  Â  Â  Â  Â  st.warning("ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.")
Â  Â  Â  Â  Â  Â  except sr.RequestError:
Â  Â  Â  Â  Â  Â  Â  Â  st.warning("ì„œë²„ ë¬¸ì œë¡œ ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


# ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© ì—¬ë¶€
autocomplete = st.toggle("ì˜ˆì‹œë¡œ ì±„ìš°ê¸°ë¥¼ í†µí•´ í”„ë¡¬í”„íŠ¸ ì˜ í™œìš©í•´ë³¼ê¹Œ?")
example = {
Â  Â  "prompt": "í•¸ë“œí°ì—ì„œ ë©”ì¸ë³´ë“œê°€ í•˜ëŠ” ì—­í• ì„ 100ì ë‚´ì™¸ë¡œ ë§í•´ì¤˜!"
}

# ---------------- ë©”ì¸ ì˜ì—­: í…ìŠ¤íŠ¸ ì§ˆë¬¸ ì…ë ¥ í¼ ------------------
with st.form('form', clear_on_submit=True):
Â  Â  user_input = st.text_input('ğŸ˜ì „ì ë¶€í’ˆì´ í•´ë‹¹ ê¸°ê¸°ì—ì„œì˜ ì—­í• ì€?',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â value=example["prompt"] if autocomplete else "",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â key='input')
Â  Â  submitted = st.form_submit_button('Send')

# ---------------- ì§ˆë¬¸ ì²˜ë¦¬ ë¡œì§ ------------------

# 1. í…ìŠ¤íŠ¸ ì§ˆë¬¸ì´ ìš°ì„ ìˆœìœ„ë¥¼ ê°€ì§
if submitted and user_input:
Â  Â  # í…ìŠ¤íŠ¸ ì§ˆë¬¸ë§Œ ì²˜ë¦¬
Â  Â  prompt = create_prompt(user_input)
Â  Â  chatbot_response = generate_response(prompt)
Â  Â  st.balloons()

Â  Â  # ì±„íŒ… ì„¸ì…˜ ì—…ë°ì´íŠ¸
Â  Â  st.session_state['past'].append(user_input)
Â  Â  st.session_state["generated"].append(chatbot_response)

# 2. í…ìŠ¤íŠ¸ ì§ˆë¬¸ì´ ì—†ì„ ê²½ìš°ì—ë§Œ ìŒì„± ì§ˆë¬¸ ì²˜ë¦¬
elif st.session_state['audio_questions']:
Â  Â  # ìŒì„± ë…¹ìŒì´ ì—¬ëŸ¬ ë²ˆ ë“¤ì–´ì™”ë‹¤ë©´, ìˆœì„œëŒ€ë¡œ ì „ë¶€ ì²˜ë¦¬
Â  Â  # í•„ìš”ì— ë”°ë¼ í•œ ê°œë§Œ ì²˜ë¦¬í•˜ê³  ì‹¶ìœ¼ë©´ forë¬¸ ëŒ€ì‹  í•œ ê°œë§Œ popí•´ì„œ ì“°ë©´ ë¨
Â  Â  for question in st.session_state['audio_questions']:
Â  Â  Â  Â  prompt = create_prompt(question)
Â  Â  Â  Â  chatbot_response = generate_response(prompt)

Â  Â  Â  Â  st.session_state['past'].append(question)
Â  Â  Â  Â  st.session_state["generated"].append(chatbot_response)

Â  Â  # ì²˜ë¦¬ í›„ ìŒì„± ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
Â  Â  st.session_state['audio_questions'].clear()


# ---------------- ì±„íŒ… ë©”ì‹œì§€ ì¶œë ¥(ê³¼ê±°ìˆœì„œ ì—­ìˆœìœ¼ë¡œ) ------------------
if st.session_state['generated']:
Â  Â  for i in reversed(range(len(st.session_state['generated']))):
Â  Â  Â  Â  message(st.session_state['past'][i], is_user=True, key=str(i) + '_user')
Â  Â  Â  Â  message(st.session_state["generated"][i], key=str(i))

# ---------------- ëŒ€í™” ë‚´ìš© ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ ------------------
def save_and_download_chat(past, generated):
Â  Â  chat_content = ""
Â  Â  for user_msg, chatbot_msg in zip(past, generated):
Â  Â  Â  Â  chat_content += "ì‚¬ìš©ì: " + user_msg + "\n"
Â  Â  Â  Â  chat_content += "ì±—ë´‡: " + chatbot_msg + "\n"
Â  Â  Â  Â  chat_content += "---" + "\n"

Â  Â  b64 = base64.b64encode(chat_content.encode()).decode()
Â  Â  href = f'<a href="data:file/txt;base64,{b64}" download="chat_history.txt">ëŒ€í™” ë‚´ìš© ë‹¤ìš´ë¡œë“œ</a>'
Â  Â  st.markdown(href, unsafe_allow_html=True)

if st.button('ì±—ë´‡ ë‚´ìš©ì„ ì €ì¥'):
Â  Â  save_and_download_chat(st.session_state['past'], st.session_state['generated'])
