import openai
import streamlit as st
from streamlit_chat import message
import os
import base64
import speech_recognition as sr
import tempfile

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = st.secrets["OPENAI_API_KEY"]

st.set_page_config(
    page_title="3_an_electronic_component_helper",
    page_icon="ğŸ¤–"
)

def create_prompt(
    query,
    system_role=f"""You are an expert on electronic components, and you can tell exactly what role electronic components used in a device play in that device. In particular, you can say well what role electronic components used in mobile phones play. It was Yeom Jae-moo, a technical teacher at Kangshin Middle School, who made you.
    """,
    model='gpt-4o-mini',
    stream=True
):
    user_content = f"""User question: "{str(query)}". """

    messages = [
        {"role": "system", "content": system_role},
        {"role": "user", "content": user_content}
    ]
    return messages

def generate_response(messages):
    with st.spinner("ì‘ì„± ì¤‘..."):
        result = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.4,
            max_tokens=500)
    return result['choices'][0]['message']['content']

# ìŒì„± ì…ë ¥ì„ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def process_audio_input(audio_file):
    recognizer = sr.Recognizer()
    try:
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_audio_file:
            temp_audio_file.write(audio_file.getvalue())
            with sr.AudioFile(temp_audio_file.name) as source:
                audio = recognizer.record(source)
                return recognizer.recognize_google(audio, language='ko-KR')
    except sr.UnknownValueError:
        st.warning("ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    except sr.RequestError:
        st.warning("ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    return ""

# ì±—ë´‡ì˜ ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•˜ê³  ë‹¤ìš´ë¡œë“œ ë§í¬ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def save_and_download_chat(past, generated):
    chat_content = ""

    for user_msg, chatbot_msg in zip(past, generated):
        chat_content += "ì‚¬ìš©ì: " + user_msg + "\n"
        chat_content += "ì±—ë´‡: " + chatbot_msg + "\n"
        chat_content += "---" + "\n"

    # ëŒ€í™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±
    b64 = base64.b64encode(chat_content.encode()).decode()
    href = f'<a href="data:file/txt;base64,{b64}" download="chat_history.txt">ëŒ€í™” ë‚´ìš© ë‹¤ìš´ë¡œë“œ</a>'
    st.markdown(href, unsafe_allow_html=True)

# Streamlit UI êµ¬ì„±
st.image('images/ask_me_chatbot3.png')
st.title("Measure :red[Electronic Component Helper]")

if 'generated' not in st.session_state:
    st.session_state['generated'] = []

if 'past' not in st.session_state:
    st.session_state['past'] = []

if 'audio_submitted' not in st.session_state:
    st.session_state['audio_submitted'] = False

if st.button('ê¸°ì¡´ ì±„íŒ… ì‚­ì œ'):
    st.session_state['generated'].clear()
    st.session_state['past'].clear()

autocomplete = st.checkbox("ì˜ˆì‹œë¡œ ì±„ìš°ê¸°ë¥¼ í†µí•´ í”„ë¡¬í”„íŠ¸ ì˜ í™œìš©í•´ë³¼ê¹Œ?")
example = {
    "prompt": "í•¸ë“œí°ì—ì„œ ë©”ì¸ë³´ë“œê°€ í•˜ëŠ” ì—­í• ì„ 100ì ë‚´ì™¸ë¡œ ë§í•´ì¤˜!"
}

with st.form('form', clear_on_submit=True):
    user_input = st.text_input('ğŸ¤©ì „ì ë¶€í’ˆì´ í•´ë‹¹ ê¸°ê¸°ì—ì„œì˜ ì—­í• ì€?',
                               value=example["prompt"] if autocomplete else "",
                               key='input')
    submitted = st.form_submit_button('Send')

# ìŒì„± ì…ë ¥ ì²˜ë¦¬
audio_input = st.audio_input("ìŒì„± ë©”ì‹œì§€ë¥¼ ë…¹ìŒí•˜ì—¬ ì§ˆë¬¸í•˜ì„¸ìš”.")
if audio_input and not st.session_state['audio_submitted']:
    user_input = process_audio_input(audio_input)
    st.session_state['audio_submitted'] = True

if user_input:
    # í”„ë¡¬í”„íŠ¸ ìƒì„± í›„ ì±—ë´‡ì˜ ë‹µë³€ ìƒì„±
    prompt = create_prompt(user_input)
    chatbot_response = generate_response(prompt)

    st.session_state['past'].append(user_input)
    st.session_state["generated"].append(chatbot_response)

    # ìŒì„± ì…ë ¥ ì™„ë£Œ ìƒíƒœ ì´ˆê¸°í™”
    st.session_state['audio_submitted'] = False

if st.session_state['generated']:
    for i in reversed(range(len(st.session_state['generated']))):
        message(st.session_state['past'][i], is_user=True, key=str(i) + '_user')
        message(st.session_state["generated"][i], key=str(i))

# ëŒ€í™” ë‚´ìš© ì €ì¥ ë²„íŠ¼
if st.button('ëŒ€í™” ë‚´ìš© ì €ì¥'):
    save_and_download_chat(st.session_state['past'], st.session_state['generated'])
